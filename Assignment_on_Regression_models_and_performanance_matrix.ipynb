{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1.  What is Simple Linear Regression (SLR)? Explain its purpose\n",
        "# Simple Linear Regression (SLR)::\n",
        "- Simple Linear Regression is a statistical method used to model the relationship between two continuous variables\n",
        "- One independent variabale (X) and one dependent variable (Y)\n",
        "- It's prpouse is to find the best fitting straiaght line that describe how the dependent variable changes as the independent variable changes\n",
        "- This line can be used to predict values of dependent variable for given values of the independent variable or to understand the strength and the direction of the linear relationship between two variables\n",
        "- The equation of the line is : Y = a + bX\n",
        "- Where Y = dependent variable(what we want to predict), X = independent variable(the input), a = intercept (values of Y when X = 0), b = slope (how much Y changes with one unit change in X)\n",
        "# Purpose::\n",
        "-Prediction: To predict the value of one variable based on another\n",
        "- Relationship Analysis: To understand how strongly you variable are related\n",
        "- Trend Estimation: To find the trend or pattern of the data\n",
        "- Effect Measurement: To measure how much one variable influence another\n",
        "\n",
        "\n",
        "# Q2. What are the key assumptions of Simple Linear Regression?\n",
        "# Assumption Of Simple Linear Regression::\n",
        "- Linearity: The relationship between the independent and dependent variables is linear.\n",
        "- Independence: The observations are independent of each other.\n",
        "- Homoscedasticity: The variance of the errors is constant across all levels of the independent variable.\n",
        "- Normality: The errors are normally distributed.\n",
        "- No multicollinearity: (Although more relevant for multiple linear regression, it's good practice to mention that for SLR, the independent variable should not be a perfect linear combination of other independent variables, which is trivially true with only one independent variable).\n",
        "\n",
        "\n",
        "\n",
        "# Q3. Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "# Mathematical Equation:\n",
        "- Y= a + bX + ε\n",
        "-Where:\n",
        "-  Y = dependent variable, the variable we are trying to predict or explain. Example: sales, marks, price, etc.\n",
        "- X = Independent variable, the variable used to predict Y. Example: advertising spend, study hours, etc.\n",
        "- a = Intercept (constant term), the value of Y when X = 0. It represents the starting point of the regression line.\n",
        "- b = Slope (regression coefficient),\n",
        "shows how much Y changes for a one-unit change in X. If b = 5, Y increases by 5 when X increases by 1.\n",
        "\n",
        "- ε(epsilon) = Error term(residual),  the difference between the actual value (Y) and the predicted value (Y^\\hat{Y}Y^). It accounts for factors not included in the model.\n",
        "\n",
        "\n",
        "# Q4. Provide a real-world example where simple linear regression can be applied\n",
        "# real world example::\n",
        "- A real estate company wants to predict the price of the house (Y) based on the size of the square feet(X).\n",
        "- Here Independent variable is (X) which is the size of the house in square feet and the dependent variable is (Y) which is the selling price of the house\n",
        "- After collecting the data from several house the company applies the simple linear regression and gets the following equation\n",
        "- Y = 50,000 + 3000X\n",
        "- Interpretation of the data is Intercept (50,000) : A house with 0 square feet with theoretically would cost 50,000 which will represent the base price of the house and Slope (3000): for every additional 1sq.ft of area the house price increases by 3000\n",
        "# Example:\n",
        "- If a house is 1000 sq.ft than the predicted price of the house can be easily calculated by simple linear regression\n",
        "- Y = 50, 000 + 3000(1000) = 30, 50,000\n",
        "- So the predicted price of the house will be 3050000\n",
        "# Purpose:\n",
        "- Estimate fare price for properties\n",
        "- Helps to identifies the underprice or over price house\n",
        "- Make better investment decision\n",
        "\n",
        "\n",
        "#Q5. What is the method of least squares in linear regression?\n",
        "# Defination:\n",
        "- The Method of Least Squares is a mathematical technique used to find the best-fitting line through a set of data points in linear regression.\n",
        "- It works by minimizing the sum of the squares of the differences between the actual values and the predicted values.\n",
        "# Goal:\n",
        "- To find the regression line\n",
        "- Y = a + bX\n",
        "- Such that the total error between observed and predicted value is small as possible.\n",
        "# Error (Residual):\n",
        "- For each data point\n",
        "- Error (e)= Yactual - Ypredicted\n",
        "- Since some of the error are positive and some some of the error  are negative so we square them to avoid cancellation\n",
        "# Least Squares Principle:\n",
        "- Minimize the Sum of Squared Errors (SSE):\n",
        "- S =  (Yi -(a+ bXi))2\n",
        "- The value of a (intercept) and b(slope) are chosen so that S is small as possible\n",
        "# Formula to calculate a and b:\n",
        "- a =  (Y - bX)/n\n",
        "- b =  (nXY - (X)(Y))/ nX2 - (X2)\n",
        "- Where n is the number of observation and X , Y are the data points\n",
        "# Purpose:\n",
        "- To find the most accurate regression line\n",
        "- To make accurate prediction based on the relationship between X and Y\n",
        "\n",
        "\n",
        "# Q6. : What is Logistic Regression? How does it differ from Linear Regression?\n",
        "# Logistic Regression::\n",
        "- Logistic Regression is a type of statistical method used to predict categorical outcomes typically binary ones based on one or more independent variables\n",
        "- It is mainly used when the dependent variables (Y) is qualitative such as yes/no, spam/not spam, pass/fail, 0/1 etc\n",
        "- Instead of predicting  a straight line like, linear regression, logistic regression  predict a s shape (sigmoid ) curve that output values 0 and 1, representing probability\n",
        "- The formula is   \n",
        "- P(Y = 1)=1/ 1 +e(-(a + bX))\n",
        "- Where  P(Y =1) is the probability that Y = 1, e is the Euler's Number , a is the intercept , b is the slope and X is the independent variable\n",
        "- Logistic Regression is used to predict categories (probabilities)\n",
        "# How Logistic Regression Differ From Linear Regression::\n",
        "- Purpose of Linear Regression is to predict a continuous value and the purpose of Logistic Regression is to predict Categorical Outcomes (Probability).\n",
        "- Types of problem that Linear Regression encounters is Regression (continuous Output) and the types of problem that Logistic Regression encounters is Classification (0 or 1)\n",
        "- The output range of Linear Regression is from negative infinity to positive infinity and the output range of Logistic regression is 0 to 1( Probability).\n",
        "- The function used is Linear for Linear Regression and the function used is Logistic (Sigmoid) for Logistic Regression.\n",
        "- The error metric for Linear Regression  is Mean Squared Error and the error metric for Logistic Regression is Log-Loss / Cross-Entropy\n",
        "- The Interpretation of Linear Regression is that it Predicts a Numeric Value and the Interpretation of Logistic Regression is that it Predicts Probability of class membership.\n",
        "- The Assumption of Linear Regression is the Linearity of Relationship and the Assumption of Logistic Regression is the Linearity in the log-odds of the outcome\n",
        "\n",
        "\n",
        "# Q7.  Name and briefly describe three common evaluation metrics for regression models.\n",
        "# Common Evualation Metrics for Regression Models::\n",
        "- The three common evaluation metrics for regression model are as follows\n",
        "- 1. Mean Absolute Error(MAE)\n",
        "- 2. Mean Squared Error(MSE)\n",
        "- 3. R-squared (Coefficient of Determination)\n",
        "# 1. Mean Absolute Error(MAE)::\n",
        "- The average of the absolute difference between the predicted and the actual values\n",
        "- Formula::  MAE =n1​∑∣Yi​−Yi​^​∣\n",
        "-It tells us how far off on average our predicted data from real data\n",
        "- Measure the average magnitude of errors in a set of predictions, without considering its direction. It’s easy to intercept because it’s in the same unit as the target variables.\n",
        "#  2. Mean Squared Error(MSE)::\n",
        "- The average of the squared difference between the predicted and the actual value\n",
        "- Formula :: MSE=n1​∑(Yi​−Yi​^​)2\n",
        "- Penalize large errors more heavily than smaller ones because of squaring them. Useful when large errors are particularly undesirable\n",
        "# R-squared (Coefficient of Determination)::\n",
        "- Represent the proportion of varience in the dependent variable that is predictable from the independent variables\n",
        "- Formula :: R2=1−∑(Yi​−Yˉ)2∑(Yi​−Yi​^​)2​\n",
        "- Range from o to 1 and sometimes negative. A higher value indicates that the model explains more of the variability in the target variable.\n",
        "\n",
        "\n",
        "# Q8.  What is the purpose of the R-squared metric in regression analysis?\n",
        "# Purpose of R-squared Metrics in Regression analysis:\n",
        "- The purpose of the R-squared metric (also known as the Coefficient of Determination) in regression analysis is to measure the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
        "- In simpler terms, it tells you how well your regression model fits the observed data.\n",
        "- An R-squared value of 1 (or 100%) means that the model perfectly explains all the variability in the dependent variable.\n",
        "- An R-squared value of 0 means that the model explains none of the variability in the dependent variable, and your predictions are no better than simply using the mean of the dependent variable.\n",
        "- An R-squared value between 0 and 1 indicates the percentage of the dependent variable's variance that the model accounts for.\n",
        "- It's important to note that a high R-squared doesn't necessarily mean the model is good or that the relationship is causal. It only indicates how much of the variation in the dependent variable is explained by the independent variable(s) in the model.\n",
        "- It doesn't indicate causation: A high R-squared value only shows a strong correlation between the independent and dependent variables, not that the independent variable causes the changes in the dependent variable.\n",
        "- It can be misleading with multiple independent variables: In multiple linear regression, adding more independent variables, even irrelevant ones, will generally increase the R-squared value. This is why adjusted R-squared is often used, as it accounts for the number of predictors in the model.\n",
        "- It doesn't tell you if the model is biased: A high R-squared doesn't guarantee that your model is making accurate predictions for all data points. It's an overall measure of fit, and the model might still have systematic errors.\n",
        "- It's not useful for comparing models with different dependent variables: R-squared is specific to the dependent variable being modeled. You cannot directly compare the R-squared of a model predicting house prices to the R-squared of a model predicting stock prices.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aQARZMe4fLkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#generating some sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1,1)  # Reshaping from scikit learn\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# creating and fitting the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "#Printing the slope and intrcept\n",
        "print(\"Slope:\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqV2G5db7Vv6",
        "outputId": "45ad3a24-1722-4197-fe00-9af7ab6698ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope: 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10. How do you interpret the coefficients in a simple linear regression model?\n",
        "# Interpretation of coefficient in a Simple Linear Regression Model::\n",
        "- In the simple Linear Regression model the coefficient model is also called as slope which tells us about how much the dependent variable (Y) is expected to change when the independent variable (X) increases by one unit, holding everything else constant.\n",
        "- The Simple Linear Regression Model is written as : Y = a + bX\n",
        "- Where\n",
        "- Y = Dependent variable\n",
        "- X = Independent Variable\n",
        "- a = Intercept\n",
        "- b = Slope\n",
        "# Interception of coefficient:\n",
        "# 1.Intercept (a):\n",
        "- The value of Y when X = 0\n",
        "- It represent the straight line or the baseline of the model\n",
        "- In some cases it may not have a practical meaning if X = 0 is not realistics\n",
        "# 2.Slope (b):\n",
        "- The change in Y for one unit increase in X\n",
        "- It shows that the strength and the direction of the relationship between X and Y\n",
        "- If b> 0, X increases  Y increases (Positive Relationship)\n",
        "- If  b < 0, X increases Y decreases (Negative Relationship)\n",
        "\n"
      ],
      "metadata": {
        "id": "x0D6bNg_-Ysx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **THE END **\n",
        "  **THANK YOU**"
      ],
      "metadata": {
        "id": "_sqYObjeE5vL"
      }
    }
  ]
}